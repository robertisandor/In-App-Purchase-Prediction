{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T00:17:35.665390Z",
     "start_time": "2019-02-19T00:17:35.321564Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import timeit\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import time\n",
    "import ast\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T00:17:56.161657Z",
     "start_time": "2019-02-19T00:17:56.154678Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "ss = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T00:18:46.632940Z",
     "start_time": "2019-02-19T00:18:06.611632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5009421"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "events_rdd = sc.textFile(\"s3a://msds630-kaggle-competition/events_adj_mn_v2.csv/part-00000\")\\\n",
    "               .map(lambda line : line.encode('ascii', 'ignore'))\n",
    "events_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T00:21:20.771551Z",
     "start_time": "2019-02-19T00:21:20.740929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# adj2\n",
    "def convertTime(ts_str):\n",
    "    return datetime.utcfromtimestamp(int(ts_str)/1000.0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# adj3\n",
    "def get8index(event_list):\n",
    "    list_8 = []\n",
    "    for i in range(len(event_list)):\n",
    "        if event_list[i] == '8':\n",
    "            list_8.append(i)\n",
    "    return list_8\n",
    "\n",
    "def getPurchaseTime(event_list, event_ts_list):\n",
    "    purchase_time_list = []\n",
    "    for index in get8index(event_list):\n",
    "        purchase_time_list.append(event_ts_list[index])\n",
    "    return purchase_time_list\n",
    "\n",
    "def getPurchaseValue(event_list, event_val_list):\n",
    "    purchase_val_list = []\n",
    "    for index in get8index(event_list):\n",
    "        purchase_val_list.append(event_val_list[index])\n",
    "    return purchase_val_list\n",
    "\n",
    "# adj4\n",
    "def inInterval(start_dt, end_dt, purchase_ts_list):\n",
    "    for dt in purchase_ts_list:\n",
    "        if dt[:10] > start_dt and dt[:10] < end_dt:\n",
    "            return 1.0\n",
    "    return -1.0\n",
    "\n",
    "# adj5\n",
    "def is_weekend(sample_pts_list):\n",
    "    if sample_pts_list == []:\n",
    "        return \"\"\n",
    "    dow = []\n",
    "    for dt in sample_pts_list:\n",
    "        dow.append(datetime.strptime(dt, '%Y-%m-%d %H:%M:%S').weekday())\n",
    "    dow = dow[0]\n",
    "    if dow in [i for i in range(5)]:\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return \"1\"\n",
    "    \n",
    "def sumPurVal(pur_val_list):\n",
    "    return sum([float(num) for num in pur_val_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T00:23:09.786637Z",
     "start_time": "2019-02-19T00:23:09.763114Z"
    }
   },
   "outputs": [],
   "source": [
    "events_rdd_adj = events_rdd.map(lambda x: ast.literal_eval(x))\n",
    "\n",
    "events_rdd_adj1 = events_rdd_adj.map(lambda x: [x[0], x[1].split(\" | \"), \n",
    "                                                x[2].split(\" | \"), x[3].split(\" | \"),\n",
    "                                                x[4]])\n",
    "\n",
    "events_rdd_adj2 = events_rdd_adj1.map(lambda x: [x[0], x[1], [convertTime(ts_str) for ts_str in x[2]], \n",
    "                                                 x[3], x[4]])\n",
    "\n",
    "# Add new column purchase_time_list\n",
    "# Add new column purchase_val_list\n",
    "events_rdd_adj3 = events_rdd_adj2.map(lambda x: [x[0], x[1], x[2], x[3], x[4], \n",
    "                                                 getPurchaseTime(x[1], x[2]),\n",
    "                                                 getPurchaseValue(x[1], x[3])])\n",
    "\n",
    "# Add new columns\n",
    "# boolean regarding if this session is a purchase during Dec.2 - 8 (1.0 - yes; -1.0 - no)\n",
    "# boolean regarding if this session is a purchase during Dec.2 - 15 (1.0 - yes; -1.0 - no)\n",
    "events_rdd_adj4 = events_rdd_adj3.map(lambda x: [x[0], x[1], x[2], x[3], x[4], x[5], x[6],\n",
    "                                                 inInterval(\"2018-12-01\", \"2018-12-09\", x[5]),\n",
    "                                                 inInterval(\"2018-12-01\", \"2018-12-16\", x[5])])\n",
    "# Convert x[1] to number of event\n",
    "# Drop x[2]\n",
    "# Drop x[3]\n",
    "# Add number of 8's\n",
    "# Add is_weekend\n",
    "# Add sum of purchase value\n",
    "events_rdd_adj5 = events_rdd_adj4.map(lambda x: [x[0], len(x[1]), len(x[5]), \n",
    "                                                 is_weekend(x[5]), x[4], x[5], sumPurVal(x[6]),\n",
    "                                                 x[7], x[8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary  \n",
    "0 - session_id  \n",
    "1 - number of events  \n",
    "2 - number of purchases (number of events with 8)  \n",
    "3 - boolean regarding weekend ('NP' - no purchase; '0' - weekday; '1' - weekend)  \n",
    "4 - boolean regarding if this session has an purchase (1.0 - yes; -1.0 - no)  \n",
    "5 - list of purchase time  \n",
    "6 - sum of purchase value  \n",
    "7 - boolean regarding if this session is a purchase during Dec.2 - 8 (1.0 - yes; -1.0 - no)  \n",
    "8 - boolean regarding if this session is a purchase during Dec.2 - 15 (1.0 - yes; -1.0 - no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T00:23:22.217206Z",
     "start_time": "2019-02-19T00:23:14.086970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6035474937349177697',\n",
       "  58,\n",
       "  1,\n",
       "  '0',\n",
       "  1.0,\n",
       "  ['2018-11-23 23:19:41'],\n",
       "  0.0,\n",
       "  -1.0,\n",
       "  -1.0],\n",
       " ['137347936755241518',\n",
       "  19,\n",
       "  1,\n",
       "  '0',\n",
       "  1.0,\n",
       "  ['2018-11-09 05:02:20'],\n",
       "  1.3930000066757202,\n",
       "  -1.0,\n",
       "  -1.0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_rdd_adj5.filter(lambda x: x[4] == 1.0).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
