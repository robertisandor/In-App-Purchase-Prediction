{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:27:46.187716Z",
     "start_time": "2019-02-25T01:27:45.377259Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import s3fs\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import calendar\n",
    "import boto3\n",
    "import io\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:29:09.769635Z",
     "start_time": "2019-02-25T01:29:09.765238Z"
    }
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:28:45.829936Z",
     "start_time": "2019-02-25T01:28:45.329989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>user_purchase_binary_7_days</th>\n",
       "      <th>user_purchase_binary_14_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e469dfaed039ead9110165d9bc457acb11609ca34057dc...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  \\\n",
       "0  e469dfaed039ead9110165d9bc457acb11609ca34057dc...   \n",
       "\n",
       "   user_purchase_binary_7_days  user_purchase_binary_14_days  \n",
       "0                         0.01                          0.02  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_df = pd.read_csv('data/sample_submission_2_adj.csv').drop([\"Unnamed: 0\"], axis = 1)\n",
    "sample_sub_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:32:50.611257Z",
     "start_time": "2019-02-25T01:32:50.387903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>user_purchase_binary_7_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bf676611754201cc93ca1e2bcce8ca2c7ff0105186ebc0...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  \\\n",
       "0  bf676611754201cc93ca1e2bcce8ca2c7ff0105186ebc0...   \n",
       "\n",
       "   user_purchase_binary_7_days  \n",
       "0                          1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read labels\n",
    "label_1_df = pd.read_csv(\"data/label_1.csv\", header = None)\\\n",
    "               .rename(columns = {0:\"user_id_hash\", \n",
    "                                  1:\"user_purchase_binary_7_days\"})\n",
    "label_2_df = pd.read_csv(\"data/label_2.csv\", header = None)\\\n",
    "               .rename(columns = {0:\"user_id_hash\", \n",
    "                                  1:\"user_purchase_binary_14_days\"})\n",
    "label_1_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary for Total\n",
    "0 - user_id  \n",
    "1 - total number of sessions  \n",
    "2 - total number of events  \n",
    "3 - median number of events  \n",
    "4 - total sum of purchases  \n",
    "5 - total amount of purchases  \n",
    "6 - median session duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:33:44.663158Z",
     "start_time": "2019-02-25T01:33:42.302956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>num_sessions</th>\n",
       "      <th>num_events</th>\n",
       "      <th>median_num_events</th>\n",
       "      <th>num_purchases</th>\n",
       "      <th>amt_purchases</th>\n",
       "      <th>median_session_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0d261313961125c71f330a8a8d59857bc48fefd0b4278c...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1626343.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  num_sessions  \\\n",
       "0  0d261313961125c71f330a8a8d59857bc48fefd0b4278c...             1   \n",
       "\n",
       "   num_events  median_num_events  num_purchases  amt_purchases  \\\n",
       "0          35               35.0              0            0.0   \n",
       "\n",
       "   median_session_duration  \n",
       "0                1626343.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Total\n",
    "total_train_df = pd.read_csv(\"data/train_total.csv\", header = None)\\\n",
    "                   .rename(columns = {0:\"user_id_hash\", \n",
    "                                      1:\"num_sessions\",\n",
    "                                      2:\"num_events\",\n",
    "                                      3:\"median_num_events\",\n",
    "                                      4:\"num_purchases\",\n",
    "                                      5:\"amt_purchases\",\n",
    "                                      6:\"median_session_duration\"})\n",
    "total_test_df = pd.read_csv(\"data/test_total.csv\", header = None)\\\n",
    "                  .rename(columns = {0:\"user_id_hash\", \n",
    "                                     1:\"num_sessions\",\n",
    "                                     2:\"num_events\",\n",
    "                                     3:\"median_num_events\",\n",
    "                                     4:\"num_purchases\",\n",
    "                                     5:\"amt_purchases\",\n",
    "                                     6:\"median_session_duration\"})\n",
    "total_train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:02:32.753439Z",
     "start_time": "2019-02-25T02:02:32.394799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>num_sessions_7</th>\n",
       "      <th>num_events_7</th>\n",
       "      <th>median_num_events_7</th>\n",
       "      <th>num_purchases_7</th>\n",
       "      <th>amt_purchases_7</th>\n",
       "      <th>median_session_duration_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c7385007b6f158e913411d1563d1f5ef90ea003050b105...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  num_sessions_7  \\\n",
       "0  c7385007b6f158e913411d1563d1f5ef90ea003050b105...               1   \n",
       "\n",
       "   num_events_7  median_num_events_7  num_purchases_7  amt_purchases_7  \\\n",
       "0             1                  1.0                0              0.0   \n",
       "\n",
       "   median_session_duration_7  \n",
       "0                        0.0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Last 7 Days\n",
    "train_7_df = pd.read_csv(\"feature_eng/train_last_7_days.csv\", header = None)\\\n",
    "                   .rename(columns = {0:\"user_id_hash\", \n",
    "                                      1:\"num_sessions_7\",\n",
    "                                      2:\"num_events_7\",\n",
    "                                      3:\"median_num_events_7\",\n",
    "                                      4:\"num_purchases_7\",\n",
    "                                      5:\"amt_purchases_7\",\n",
    "                                      6:\"median_session_duration_7\"})\n",
    "test_7_df = pd.read_csv(\"feature_eng/test_last_7_days.csv\", header = None)\\\n",
    "                  .rename(columns = {0:\"user_id_hash\", \n",
    "                                     1:\"num_sessions_7\",\n",
    "                                     2:\"num_events_7\",\n",
    "                                     3:\"median_num_events_7\",\n",
    "                                     4:\"num_purchases_7\",\n",
    "                                     5:\"amt_purchases_7\",\n",
    "                                     6:\"median_session_duration_7\"})\n",
    "train_7_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:51:01.412607Z",
     "start_time": "2019-02-25T02:51:00.816384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>num_sessions_14</th>\n",
       "      <th>num_events_14</th>\n",
       "      <th>median_num_events_14</th>\n",
       "      <th>num_purchases_14</th>\n",
       "      <th>amt_purchases_14</th>\n",
       "      <th>median_session_duration_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7d68ea7dcf1bc9fc2d455c19d1ba409951609735a543b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  num_sessions_14  \\\n",
       "0  a7d68ea7dcf1bc9fc2d455c19d1ba409951609735a543b...                1   \n",
       "\n",
       "   num_events_14  median_num_events_14  num_purchases_14  amt_purchases_14  \\\n",
       "0              1                   1.0                 0               0.0   \n",
       "\n",
       "   median_session_duration_14  \n",
       "0                         0.0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Last 14 Days\n",
    "train_14_df = pd.read_csv(\"feature_eng/train_last_14_days.csv\", header = None)\\\n",
    "                   .rename(columns = {0:\"user_id_hash\", \n",
    "                                      1:\"num_sessions_14\",\n",
    "                                      2:\"num_events_14\",\n",
    "                                      3:\"median_num_events_14\",\n",
    "                                      4:\"num_purchases_14\",\n",
    "                                      5:\"amt_purchases_14\",\n",
    "                                      6:\"median_session_duration_14\"})\n",
    "test_14_df = pd.read_csv(\"feature_eng/test_last_14_days.csv\", header = None)\\\n",
    "                  .rename(columns = {0:\"user_id_hash\", \n",
    "                                     1:\"num_sessions_14\",\n",
    "                                     2:\"num_events_14\",\n",
    "                                     3:\"median_num_events_14\",\n",
    "                                     4:\"num_purchases_14\",\n",
    "                                     5:\"amt_purchases_14\",\n",
    "                                     6:\"median_session_duration_14\"})\n",
    "train_14_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:54:06.786896Z",
     "start_time": "2019-02-25T02:54:06.769823Z"
    }
   },
   "source": [
    "### Data Dictionary for Sessions\n",
    "0 - user_id  \n",
    "1 - date_user_created   \n",
    "2 - most_freq_country  \n",
    "3 - most_freq_os  \n",
    "4 - num_uniq_device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:56:30.610107Z",
     "start_time": "2019-02-25T02:56:29.036266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>date_user_created</th>\n",
       "      <th>most_freq_country</th>\n",
       "      <th>most_freq_os</th>\n",
       "      <th>num_uniq_device_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46d54b4fab292c461cdf8f3825f7106907b300b2d28cf3...</td>\n",
       "      <td>2018-10-19 22:04:58</td>\n",
       "      <td>US</td>\n",
       "      <td>iOS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash    date_user_created  \\\n",
       "0  46d54b4fab292c461cdf8f3825f7106907b300b2d28cf3...  2018-10-19 22:04:58   \n",
       "\n",
       "  most_freq_country most_freq_os  num_uniq_device_id  \n",
       "0                US          iOS                   1  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Sessions\n",
    "sessions_df = pd.read_csv(\"feature_eng/sessions.csv\", header = None)\\\n",
    "                   .rename(columns = {0:\"user_id_hash\", \n",
    "                                      1:\"date_user_created\",\n",
    "                                      2:\"most_freq_country\",\n",
    "                                      3:\"most_freq_os\",\n",
    "                                      4:\"num_uniq_device_id\"})\\\n",
    "                   .dropna()\n",
    "sessions_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:05.280357Z",
     "start_time": "2019-02-25T03:14:57.228157Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fe = pd.merge(total_train_df, sessions_df, how = \"left\").dropna()\n",
    "train_fe = pd.merge(train_fe, train_7_df, how = \"left\").fillna(0)\n",
    "train_fe = pd.merge(train_fe, train_14_df, how = \"left\").fillna(0)\n",
    "test_fe = pd.merge(total_test_df, sessions_df, how = \"left\").dropna()\n",
    "test_fe = pd.merge(test_fe, test_7_df, how = \"left\").fillna(0)\n",
    "test_fe = pd.merge(test_fe, test_14_df, how = \"left\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:05.819126Z",
     "start_time": "2019-02-25T03:15:05.284235Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check null values\n",
    "for column in train_fe.columns:\n",
    "    if train_fe[column].isnull().any():\n",
    "        print('{0} has {1} null values'.format(column, train_fe[column].isnull().sum()))\n",
    "for column in test_fe.columns:\n",
    "    if test_fe[column].isnull().any():\n",
    "        print('{0} has {1} null values'.format(column, test_fe[column].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create column for Number of Days Existed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:18.741257Z",
     "start_time": "2019-02-25T03:15:05.820828Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create column for Number of Days Existed\n",
    "# For training, compute days between first date and Dec.2\n",
    "# For testing, compute days between first date and Dec.16\n",
    "train_fe[\"num_days_existed\"] = [(datetime(2018, 12, 2) - datetime.strptime(date, '%Y-%m-%d %H:%M:%S')).days \n",
    "                                for date in train_fe.date_user_created.values]\n",
    "test_fe[\"num_days_existed\"] = [(datetime(2018, 12, 16) - datetime.strptime(date, '%Y-%m-%d %H:%M:%S')).days \n",
    "                                for date in test_fe.date_user_created.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create column for Days Since Most Recent Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:21.808662Z",
     "start_time": "2019-02-25T03:15:18.744116Z"
    }
   },
   "outputs": [],
   "source": [
    "most_recent_train_df = pd.read_csv('feature_eng/most_recent_session_train.csv', header = None)\\\n",
    "                         .rename(columns = {0:\"user_id_hash\", 1:\"most_recent_session\"})\n",
    "most_recent_test_df = pd.read_csv('feature_eng/most_recent_session_test.csv', header = None)\\\n",
    "                        .rename(columns = {0:\"user_id_hash\", 1:\"most_recent_session\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:24.727289Z",
     "start_time": "2019-02-25T03:15:21.812502Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fe_adj = pd.merge(train_fe, most_recent_train_df, how = 'left')\n",
    "test_fe_adj = pd.merge(test_fe, most_recent_test_df, how = 'left')\n",
    "train_fe_adj2 = train_fe_adj\n",
    "test_fe_adj2 = test_fe_adj\n",
    "train_fe_adj2[\"most_recent_session\"] = train_fe_adj[\"most_recent_session\"].fillna(train_fe_adj[\"date_user_created\"])\n",
    "test_fe_adj2[\"most_recent_session\"] = test_fe_adj[\"most_recent_session\"].fillna(test_fe_adj[\"date_user_created\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:37.072789Z",
     "start_time": "2019-02-25T03:15:24.730314Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fe[\"days_since_last_session\"] = [(datetime(2018, 12, 2) - datetime.strptime(date, '%Y-%m-%d %H:%M:%S')).days \n",
    "                                        for date in train_fe_adj2.most_recent_session.values]\n",
    "test_fe[\"days_since_last_session\"] = [(datetime(2018, 12, 16) - datetime.strptime(date, '%Y-%m-%d %H:%M:%S')).days \n",
    "                                        for date in test_fe_adj2.most_recent_session.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create column for frequent OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:37.648570Z",
     "start_time": "2019-02-25T03:15:37.074573Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fe[\"most_freq_os_android\"] = [1 if x == 'Android OS' else 0 for x in train_fe.most_freq_os.values]\n",
    "train_fe[\"most_freq_os_ios\"] = [1 if x != 'Android OS' else 0 for x in train_fe.most_freq_os.values]\n",
    "test_fe[\"most_freq_os_android\"] = [1 if x == 'Android OS' else 0 for x in test_fe.most_freq_os.values]\n",
    "test_fe[\"most_freq_os_ios\"] = [1 if x != 'Android OS' else 0 for x in test_fe.most_freq_os.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummies regarding regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:37.801016Z",
     "start_time": "2019-02-25T03:15:37.650138Z"
    }
   },
   "outputs": [],
   "source": [
    "country_code_df = pd.read_csv(\"country_code.csv\", header = None)\n",
    "country_code_df = country_code_df.loc[1:,[1,5,6]]\n",
    "country_code_df = country_code_df[country_code_df[1] != 'AQ'].dropna()\n",
    "country_code_dict = {}\n",
    "country_code_dict['ZZ'] = \"Unknown\"\n",
    "country_code_dict['XK'] = \"Southern Europe\"\n",
    "country_code_dict['NAM'] = \"Sub-Saharan Africa\"\n",
    "for country_code in country_code_df[1].values:\n",
    "    country_code_dict[country_code] = country_code_df[country_code_df[1]==country_code][6].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:37.932803Z",
     "start_time": "2019-02-25T03:15:37.802223Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fe[\"most_freq_region\"] = [country_code_dict[x] for x in train_fe.most_freq_country.values]\n",
    "test_fe[\"most_freq_region\"] = [country_code_dict[x] for x in test_fe.most_freq_country.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:38.305464Z",
     "start_time": "2019-02-25T03:15:37.934340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Western Europe 21095\n",
      "Sub-Saharan Africa 23872\n",
      "South-eastern Asia 55423\n",
      "Northern America 297832\n",
      "Latin America and the Caribbean 24213\n",
      "Australia and New Zealand 20900\n",
      "Southern Asia 57538\n",
      "Northern Europe 60393\n"
     ]
    }
   ],
   "source": [
    "region_list = []\n",
    "for region in set(train_fe.most_freq_region.values):\n",
    "    if list(train_fe.most_freq_region.values).count(region) > 20000:\n",
    "        print(region, list(train_fe.most_freq_region.values).count(region))\n",
    "        region_list.append(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:40.544585Z",
     "start_time": "2019-02-25T03:15:38.307234Z"
    }
   },
   "outputs": [],
   "source": [
    "for region in region_list:\n",
    "    col_name = f\"is_{region.replace(' ','_').lower()}\"\n",
    "    train_fe[col_name] = [1 if x == region else 0 for x in train_fe.most_freq_region.values]\n",
    "    test_fe[col_name] = [1 if x == region else 0 for x in test_fe.most_freq_region.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:40.564862Z",
     "start_time": "2019-02-25T03:15:40.546207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>num_sessions</th>\n",
       "      <th>num_events</th>\n",
       "      <th>median_num_events</th>\n",
       "      <th>num_purchases</th>\n",
       "      <th>amt_purchases</th>\n",
       "      <th>median_session_duration</th>\n",
       "      <th>date_user_created</th>\n",
       "      <th>most_freq_country</th>\n",
       "      <th>most_freq_os</th>\n",
       "      <th>...</th>\n",
       "      <th>most_freq_os_ios</th>\n",
       "      <th>most_freq_region</th>\n",
       "      <th>is_western_europe</th>\n",
       "      <th>is_sub-saharan_africa</th>\n",
       "      <th>is_south-eastern_asia</th>\n",
       "      <th>is_northern_america</th>\n",
       "      <th>is_latin_america_and_the_caribbean</th>\n",
       "      <th>is_australia_and_new_zealand</th>\n",
       "      <th>is_southern_asia</th>\n",
       "      <th>is_northern_europe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0d261313961125c71f330a8a8d59857bc48fefd0b4278c...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1626343.0</td>\n",
       "      <td>2018-10-13 07:33:07</td>\n",
       "      <td>ID</td>\n",
       "      <td>iOS</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>South-eastern Asia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  num_sessions  \\\n",
       "0  0d261313961125c71f330a8a8d59857bc48fefd0b4278c...             1   \n",
       "\n",
       "   num_events  median_num_events  num_purchases  amt_purchases  \\\n",
       "0          35               35.0              0            0.0   \n",
       "\n",
       "   median_session_duration    date_user_created most_freq_country  \\\n",
       "0                1626343.0  2018-10-13 07:33:07                ID   \n",
       "\n",
       "  most_freq_os         ...          most_freq_os_ios    most_freq_region  \\\n",
       "0          iOS         ...                         1  South-eastern Asia   \n",
       "\n",
       "   is_western_europe  is_sub-saharan_africa  is_south-eastern_asia  \\\n",
       "0                  0                      0                      1   \n",
       "\n",
       "   is_northern_america  is_latin_america_and_the_caribbean  \\\n",
       "0                    0                                   0   \n",
       "\n",
       "   is_australia_and_new_zealand  is_southern_asia  is_northern_europe  \n",
       "0                             0                 0                   0  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fe.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:15:43.802625Z",
     "start_time": "2019-02-25T03:15:40.567080Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fe = pd.merge(train_fe, label_1_df, how = 'left').fillna(0)\n",
    "train_fe = pd.merge(train_fe, label_2_df, how = 'left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:01:06.595725Z",
     "start_time": "2019-02-26T01:01:06.182476Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ml = train_fe.copy()\n",
    "test_ml = test_fe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:01:06.622719Z",
     "start_time": "2019-02-26T01:01:06.599673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0}"
      ]
     },
     "execution_count": 1393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the labels are correct. The expected outcome is {0.0}.\n",
    "set(train_ml[train_ml.user_purchase_binary_7_days != train_ml.user_purchase_binary_14_days]\\\n",
    " .user_purchase_binary_7_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:01:06.974428Z",
     "start_time": "2019-02-26T01:01:06.966540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id_hash', 'num_sessions', 'num_events', 'median_num_events',\n",
       "       'num_purchases', 'amt_purchases', 'median_session_duration',\n",
       "       'date_user_created', 'most_freq_country', 'most_freq_os',\n",
       "       'num_uniq_device_id', 'num_sessions_7', 'num_events_7',\n",
       "       'median_num_events_7', 'num_purchases_7', 'amt_purchases_7',\n",
       "       'median_session_duration_7', 'num_sessions_14', 'num_events_14',\n",
       "       'median_num_events_14', 'num_purchases_14', 'amt_purchases_14',\n",
       "       'median_session_duration_14', 'num_days_existed',\n",
       "       'days_since_last_session', 'most_freq_os_android', 'most_freq_os_ios',\n",
       "       'most_freq_region', 'is_western_europe', 'is_sub-saharan_africa',\n",
       "       'is_south-eastern_asia', 'is_northern_america',\n",
       "       'is_latin_america_and_the_caribbean', 'is_australia_and_new_zealand',\n",
       "       'is_southern_asia', 'is_northern_europe', 'user_purchase_binary_7_days',\n",
       "       'user_purchase_binary_14_days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:01:08.571463Z",
     "start_time": "2019-02-26T01:01:07.618237Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ml[\"is_purchase_7\"] = [1.0 if y > 0 else 0.0 for y in train_ml.num_purchases_7]\n",
    "train_ml[\"is_purchase_ever\"] = [1.0 if y > 0 else 0.0 for y in train_ml.num_purchases]\n",
    "train_ml[\"is_session_7\"] = [1.0 if y > 0 else 0.0 for y in train_ml.num_sessions_7]\n",
    "train_ml[\"is_purchase_14\"] = [1.0 if y > 0 else 0.0 for y in train_ml.num_purchases_14]\n",
    "train_ml[\"is_session_14\"] = [1.0 if y > 0 else 0.0 for y in train_ml.num_sessions_14]\n",
    "train_ml['purchase_per_day'] = train_ml.num_purchases/train_ml.num_days_existed\n",
    "test_ml[\"is_purchase_7\"] = [1.0 if y > 0 else 0.0 for y in test_ml.num_purchases_7]\n",
    "test_ml[\"is_purchase_ever\"] = [1.0 if y > 0 else 0.0 for y in test_ml.num_purchases]\n",
    "test_ml[\"is_session_7\"] = [1.0 if y > 0 else 0.0 for y in test_ml.num_sessions_7]\n",
    "test_ml[\"is_purchase_14\"] = [1.0 if y > 0 else 0.0 for y in test_ml.num_purchases_14]\n",
    "test_ml[\"is_session_14\"] = [1.0 if y > 0 else 0.0 for y in test_ml.num_sessions_14]\n",
    "test_ml['purchase_per_day'] = test_ml.num_purchases/test_ml.num_days_existed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:01:10.478502Z",
     "start_time": "2019-02-26T01:01:08.853936Z"
    }
   },
   "outputs": [],
   "source": [
    "# per num_days_existed\n",
    "train_ml[\"num_uniq_session_db_num_days_existed\"] = train_ml.num_sessions / train_ml.num_days_existed\n",
    "test_ml[\"num_uniq_session_db_num_days_existed\"] = test_ml.num_sessions / test_ml.num_days_existed\n",
    "train_ml[\"total_purchase_amt_db_num_days_existed\"] = train_ml.amt_purchases / train_ml.num_days_existed\n",
    "test_ml[\"total_purchase_amt_db_num_days_existed\"] = test_ml.amt_purchases / test_ml.num_days_existed\n",
    "# per num_uniq_session_id\n",
    "train_ml[\"total_purchase_amt_db_num_uniq_session_id\"] = train_ml.amt_purchases / train_ml.num_sessions\n",
    "test_ml[\"total_purchase_amt_db_num_uniq_session_id\"] = test_ml.amt_purchases / test_ml.num_sessions\n",
    "train_ml[\"total_purchase_amt_db_total_num_purchase\"] = train_ml.amt_purchases / train_ml.num_purchases\n",
    "test_ml[\"total_purchase_amt_db_total_num_purchase\"] = test_ml.amt_purchases / test_ml.num_purchases\n",
    "train_ml = train_ml.fillna(0)\n",
    "test_ml = test_ml.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:14:15.726759Z",
     "start_time": "2019-02-26T01:14:13.673160Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ml[\"amt_purchase_past_wk_per_purchase\"] = train_ml.amt_purchases_7 / train_ml.num_purchases_7\n",
    "test_ml[\"amt_purchase_past_wk_per_purchase\"] = test_ml.amt_purchases_7 / test_ml.num_purchases_7\n",
    "train_ml[\"amt_purchase_past_wk_per_session\"] = train_ml.amt_purchases_7 / train_ml.num_sessions_7\n",
    "test_ml[\"amt_purchase_past_wk_per_session\"] = test_ml.amt_purchases_7 / test_ml.num_sessions_7\n",
    "train_ml = train_ml.fillna(0)\n",
    "test_ml = test_ml.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:40:42.710033Z",
     "start_time": "2019-02-26T01:40:42.569122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set labels\n",
    "labels_1 = train_ml.user_purchase_binary_7_days\n",
    "labels_2 = train_ml.user_purchase_binary_14_days\n",
    "features_train = train_ml[['purchase_per_day', 'days_since_last_session', \n",
    "                           'is_purchase_ever', 'is_session_7',\n",
    "                           'num_purchases_7', 'most_freq_os_android',\n",
    "                           'is_western_europe', 'is_sub-saharan_africa',\n",
    "                           'is_south-eastern_asia', 'is_northern_america',\n",
    "                           'is_latin_america_and_the_caribbean', 'is_australia_and_new_zealand',\n",
    "                           'is_southern_asia', 'is_northern_europe',\n",
    "                           \"num_uniq_session_db_num_days_existed\",\n",
    "                           \"total_purchase_amt_db_num_days_existed\",\n",
    "                           \"total_purchase_amt_db_num_uniq_session_id\",\n",
    "                           \"total_purchase_amt_db_total_num_purchase\",\n",
    "                           \"amt_purchase_past_wk_per_purchase\",\n",
    "                           \"amt_purchase_past_wk_per_session\"\n",
    "                          ]]\n",
    "features_test = test_ml[['purchase_per_day', 'days_since_last_session', \n",
    "                         'is_purchase_ever', 'is_session_7',\n",
    "                         'num_purchases_7', 'most_freq_os_android',\n",
    "                         'is_western_europe', 'is_sub-saharan_africa',\n",
    "                         'is_south-eastern_asia', 'is_northern_america',\n",
    "                         'is_latin_america_and_the_caribbean', 'is_australia_and_new_zealand',\n",
    "                         'is_southern_asia', 'is_northern_europe',\n",
    "                         \"num_uniq_session_db_num_days_existed\",\n",
    "                         \"total_purchase_amt_db_num_days_existed\",\n",
    "                         \"total_purchase_amt_db_num_uniq_session_id\",\n",
    "                         \"total_purchase_amt_db_total_num_purchase\",\n",
    "                         \"amt_purchase_past_wk_per_purchase\",\n",
    "                         \"amt_purchase_past_wk_per_session\"\n",
    "                        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:41:08.629772Z",
     "start_time": "2019-02-26T01:40:43.326111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF_Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.682662</td>\n",
       "      <td>purchase_per_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.673646</td>\n",
       "      <td>total_purchase_amt_db_num_days_existed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.677264</td>\n",
       "      <td>days_since_last_session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.879877</td>\n",
       "      <td>is_northern_america</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.800305</td>\n",
       "      <td>most_freq_os_android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.718239</td>\n",
       "      <td>total_purchase_amt_db_total_num_purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.313933</td>\n",
       "      <td>is_purchase_ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.306654</td>\n",
       "      <td>num_purchases_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.107003</td>\n",
       "      <td>amt_purchase_past_wk_per_session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000386</td>\n",
       "      <td>is_session_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.906794</td>\n",
       "      <td>amt_purchase_past_wk_per_purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.766415</td>\n",
       "      <td>total_purchase_amt_db_num_uniq_session_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.614819</td>\n",
       "      <td>num_uniq_session_db_num_days_existed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.509266</td>\n",
       "      <td>is_southern_asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.456878</td>\n",
       "      <td>is_south-eastern_asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.391238</td>\n",
       "      <td>is_northern_europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.210919</td>\n",
       "      <td>is_sub-saharan_africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.205561</td>\n",
       "      <td>is_latin_america_and_the_caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.145128</td>\n",
       "      <td>is_western_europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.135443</td>\n",
       "      <td>is_australia_and_new_zealand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF_Factor                                   features\n",
       "0     5.682662                           purchase_per_day\n",
       "15    4.673646     total_purchase_amt_db_num_days_existed\n",
       "1     3.677264                    days_since_last_session\n",
       "9     2.879877                        is_northern_america\n",
       "5     2.800305                       most_freq_os_android\n",
       "17    2.718239   total_purchase_amt_db_total_num_purchase\n",
       "2     2.313933                           is_purchase_ever\n",
       "4     2.306654                            num_purchases_7\n",
       "19    2.107003           amt_purchase_past_wk_per_session\n",
       "3     2.000386                               is_session_7\n",
       "18    1.906794          amt_purchase_past_wk_per_purchase\n",
       "16    1.766415  total_purchase_amt_db_num_uniq_session_id\n",
       "14    1.614819       num_uniq_session_db_num_days_existed\n",
       "12    1.509266                           is_southern_asia\n",
       "8     1.456878                      is_south-eastern_asia\n",
       "13    1.391238                         is_northern_europe\n",
       "7     1.210919                      is_sub-saharan_africa\n",
       "10    1.205561         is_latin_america_and_the_caribbean\n",
       "6     1.145128                          is_western_europe\n",
       "11    1.135443               is_australia_and_new_zealand"
      ]
     },
     "execution_count": 1686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF_Factor\"] = [variance_inflation_factor(features_train.values, i) for i in range(features_train.shape[1])]\n",
    "vif[\"features\"] = features_train.columns\n",
    "vif.sort_values(by = 'VIF_Factor', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1563,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:15:10.364360Z",
     "start_time": "2019-02-26T01:15:10.360312Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1564,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:15:10.371283Z",
     "start_time": "2019-02-26T01:15:10.366711Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1803,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:45:44.072939Z",
     "start_time": "2019-02-26T01:45:43.670035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({0.0: 4396, 1.0: 4396})\n"
     ]
    }
   ],
   "source": [
    "# Resampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "rus = RandomUnderSampler()\n",
    "features_res_1, labels_res_1 = rus.fit_sample(features_train, labels_1)\n",
    "print(f\"Resampled dataset shape: {Counter(labels_res_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1804,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:45:44.082491Z",
     "start_time": "2019-02-26T01:45:44.076768Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(features_res_1, labels_res_1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1808,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:45:47.926450Z",
     "start_time": "2019-02-26T01:45:47.922471Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_pars_1 = {'min_child_weight': 1, 'eta': 0.001, 'colsample_bytree': 0.7, 'max_depth': 6,\n",
    "            'lambda': 0.0, 'n_estimators' : 9,\n",
    "            'subsample': 0.3, 'booster' : 'gblinear', 'silent': 1,\n",
    "            'eval_metric': 'auc', 'objective': 'binary:logistic', 'scale_pos_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1809,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:45:48.522235Z",
     "start_time": "2019-02-26T01:45:48.517562Z"
    }
   },
   "outputs": [],
   "source": [
    "dtrain_1 = xgb.DMatrix(X_train_1, label=y_train_1)\n",
    "dvalid_1 = xgb.DMatrix(X_val_1, label=y_val_1)\n",
    "watchlist = [(dtrain_1, 'train'), (dvalid_1, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1810,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:45:49.309661Z",
     "start_time": "2019-02-26T01:45:49.042477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.963129\tvalid-auc:0.970395\n",
      "[10]\ttrain-auc:0.96313\tvalid-auc:0.970428\n",
      "[20]\ttrain-auc:0.963119\tvalid-auc:0.970433\n",
      "[30]\ttrain-auc:0.963127\tvalid-auc:0.970448\n",
      "[40]\ttrain-auc:0.963111\tvalid-auc:0.970456\n",
      "[49]\ttrain-auc:0.963099\tvalid-auc:0.970454\n"
     ]
    }
   ],
   "source": [
    "gbm_1 = xgb.train(xgb_pars_1, dtrain_1, 50, watchlist,\n",
    "                maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1858,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T06:31:01.124867Z",
     "start_time": "2019-02-26T06:31:01.110927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9704536057693691"
      ]
     },
     "execution_count": 1858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_1 = gbm_1.predict(dvalid_1)\n",
    "roc_auc_score(y_val_1, pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1750,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:43:19.372290Z",
     "start_time": "2019-02-26T01:43:18.935309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: Counter({0.0: 5553, 1.0: 5553})\n"
     ]
    }
   ],
   "source": [
    "# Resampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "rus = RandomUnderSampler()\n",
    "features_res_2, labels_res_2 = rus.fit_sample(features_train, labels_2)\n",
    "print(f\"Resampled dataset shape: {Counter(labels_res_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:43:19.382509Z",
     "start_time": "2019-02-26T01:43:19.375904Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(features_res_2, labels_res_2, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1780,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:44:58.307958Z",
     "start_time": "2019-02-26T01:44:58.304419Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_pars_2 = {'min_child_weight': 1, 'eta': 0.001, 'colsample_bytree': 0.7, 'max_depth': 6,\n",
    "              'lambda': 0, 'n_estimators': 9, \n",
    "              'subsample': 0.4, 'booster' : 'gblinear', 'silent': 1,\n",
    "              'eval_metric': 'auc', 'objective': 'binary:logistic', 'scale_pos_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1781,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:44:58.765910Z",
     "start_time": "2019-02-26T01:44:58.760509Z"
    }
   },
   "outputs": [],
   "source": [
    "dtrain_2 = xgb.DMatrix(X_train_2, label=y_train_2)\n",
    "dvalid_2 = xgb.DMatrix(X_val_2, label=y_val_2)\n",
    "watchlist_2 = [(dtrain_2, 'train'), (dvalid_2, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1782,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:44:59.461300Z",
     "start_time": "2019-02-26T01:44:59.139811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.95693\tvalid-auc:0.963155\n",
      "[10]\ttrain-auc:0.956946\tvalid-auc:0.963172\n",
      "[20]\ttrain-auc:0.956964\tvalid-auc:0.963179\n",
      "[30]\ttrain-auc:0.956962\tvalid-auc:0.963192\n",
      "[40]\ttrain-auc:0.956968\tvalid-auc:0.963211\n",
      "[49]\ttrain-auc:0.956968\tvalid-auc:0.963213\n"
     ]
    }
   ],
   "source": [
    "gbm_2 = xgb.train(xgb_pars_2, dtrain_2, 50, watchlist_2,\n",
    "                maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1812,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:45:59.877357Z",
     "start_time": "2019-02-26T01:45:59.867650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963212841737521"
      ]
     },
     "execution_count": 1812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2 = gbm_2.predict(dvalid_2)\n",
    "roc_auc_score(y_val_2, pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build result data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1814,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:46:09.605960Z",
     "start_time": "2019-02-26T01:46:07.922872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
       "       'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For resampling\n",
    "_, num_cols = features_test.shape\n",
    "new_cols_name_test = [f'f{i}' for i in range(num_cols)]\n",
    "old_cols_name_test = list(features_test.columns)\n",
    "features_test_adj = features_test.copy()\n",
    "for j in range(num_cols):\n",
    "    features_test_adj = features_test_adj.rename(columns = {old_cols_name_test[j]:new_cols_name_test[j]})\n",
    "features_test_adj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1815,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:46:11.144353Z",
     "start_time": "2019-02-26T01:46:10.349396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>user_purchase_binary_7_days</th>\n",
       "      <th>user_purchase_binary_14_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c39d635765ff135752a20fea4283e35edb76f5cd0babe1...</td>\n",
       "      <td>0.459621</td>\n",
       "      <td>0.460405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0d261313961125c71f330a8a8d59857bc48fefd0b4278c...</td>\n",
       "      <td>0.449424</td>\n",
       "      <td>0.450537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a7d68ea7dcf1bc9fc2d455c19d1ba409951609735a543b...</td>\n",
       "      <td>0.479725</td>\n",
       "      <td>0.480784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fcb42eb24a4a769cd511a0dc6d6d7cd3f79cc1bfef0098...</td>\n",
       "      <td>0.463018</td>\n",
       "      <td>0.463971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fa2d2e99027a7099d3ab22b686fc2d8d03404be93931b8...</td>\n",
       "      <td>0.460067</td>\n",
       "      <td>0.461010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  \\\n",
       "0  c39d635765ff135752a20fea4283e35edb76f5cd0babe1...   \n",
       "1  0d261313961125c71f330a8a8d59857bc48fefd0b4278c...   \n",
       "2  a7d68ea7dcf1bc9fc2d455c19d1ba409951609735a543b...   \n",
       "3  fcb42eb24a4a769cd511a0dc6d6d7cd3f79cc1bfef0098...   \n",
       "4  fa2d2e99027a7099d3ab22b686fc2d8d03404be93931b8...   \n",
       "\n",
       "   user_purchase_binary_7_days  user_purchase_binary_14_days  \n",
       "0                     0.459621                      0.460405  \n",
       "1                     0.449424                      0.450537  \n",
       "2                     0.479725                      0.480784  \n",
       "3                     0.463018                      0.463971  \n",
       "4                     0.460067                      0.461010  "
      ]
     },
     "execution_count": 1815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df[\"user_id_hash\"] = test_ml.user_id_hash.values\n",
    "dtest_1 = xgb.DMatrix(features_test_adj)\n",
    "dtest_2 = xgb.DMatrix(features_test_adj)\n",
    "result_df['user_purchase_binary_7_days'] = gbm_1.predict(dtest_1)\n",
    "result_df['user_purchase_binary_14_days'] = gbm_2.predict(dtest_2)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1816,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:46:11.583843Z",
     "start_time": "2019-02-26T01:46:11.578194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619422"
      ]
     },
     "execution_count": 1816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1817,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:46:12.431014Z",
     "start_time": "2019-02-26T01:46:12.360948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312568"
      ]
     },
     "execution_count": 1817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_df_adj = pd.DataFrame()\n",
    "sample_sub_df_adj[\"user_id_hash\"] = sample_sub_df.user_id_hash.values\n",
    "len(sample_sub_df_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1818,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:46:13.535808Z",
     "start_time": "2019-02-26T01:46:12.965854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id_hash                    0\n",
       "user_purchase_binary_7_days     0\n",
       "user_purchase_binary_14_days    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result = pd.merge(sample_sub_df_adj, result_df, how = \"left\").fillna(0.0)\n",
    "final_result.isnull().sum() # Check if there is nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1821,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T01:47:05.539885Z",
     "start_time": "2019-02-26T01:47:04.206028Z"
    }
   },
   "outputs": [],
   "source": [
    "final_result.to_csv('submission/sample_submission_fatpapaya_xgb_13.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
